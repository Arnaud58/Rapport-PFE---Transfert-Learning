\SpecialSection{Conclusion}

Lors de ces derniers mois, nous avons pu voir de nombreux articles dont le but est de réduire le nombre de données nécessaire à l'entraînement efficace d'un réseau de neurones dans le cadre de la détection d'objets. De nombreux axes et de manières de faire se sont dégagées. Les articles portaient tout d'abord sur le large thème du transfer learning.

Nous avons pu constater des approches spécialisées sur des problèmes particuliers. Nous avons rapidement pu trouver des moyens de sélectionner des articles plus pertinents, que ce soit par rapport à leur résultat en terme de précision ou par rapport à la quantité d'images annotées à fournir.

C'est dans cette optique que nous avons décidé de concentrer une partie de nos efforts sur une approche particulière pour faire face au manque de données : le few-shot learning. Ce domaine permet déjà de faire de la classification sur des bases de données qui contiennent très peu d'images (de 1 à 10 par catégorie d'objets), ce qui correspond parfaitement à nos attentes. Cependant, le few-shot learning appliqué à la détection d'objets ne donne pas encore de résultats convaincants. On peut espérer cependant des progrès pour les années à venir, étant donné que le domaine n'a été exploré que très récemment.

En parallèle, nous nous sommes aussi concentrés sur d'autres manière de faire de la TL qui permettent de faire de la régression de manière efficace. Nous avons sélectionné les domaines de multi-task leaning et de Deep Learning avec adversial qui obtiennent des très bons résultats même si le nombre d'images nécessaire au bon entraînement est finalement supérieur au few-shot learning.

Nous continuerons maintenant notre travail sur la comparaison entre des méthodes de TL et de few-shot qui nous permettront de déterminer de manière expérimentale sur quels cas il est avantageux d'appliquer une méthode plutôt qu'une autre.